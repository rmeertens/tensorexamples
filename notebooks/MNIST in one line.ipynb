{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating MNIST in one line\n",
    "Python is a fantastic language which both allows you to make self-documenting understandable code, and allows you to make short powerful statements. I wanted to try to train and evaluate a neural network on the MNIST dataset. In this post I will guide you through my progress on achieving this. \n",
    "\n",
    "## Cheating\n",
    "First of all I wanted to totally admit that I'm cheating. It is possible to import things in the same place where you use it, but the end result would look even more terrible than it looks now. For the rest of this post, assume that Python would be extra-batteries-included, with tensorflow, numpy, and sklearn already included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow version used in this tutorial is 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"The TensorFlow version used in this tutorial is\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial code\n",
    "It is already quite amazing that it is so easy nowadays to train a computer to recognize written numbers. Only ten years ago I spent weeks in a neural network course implementing backpropagation and data loading. This program is already short, clear, and has all functionality I would like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4678 - accuracy: 0.8778\n",
      "The loaded model has a test accuracy of  0.9142\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Transform the input into floating point inputs between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Compile and train the model for one epoch... It's only to have something trained, not get the best score\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train,epochs=1)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(model(x_test), axis=1)\n",
    "\n",
    "# Calculate the accuracy and confusion matrics with sklearn\n",
    "accuracy_score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"The loaded model has a test accuracy of \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify the metrics\n",
    "Simplifying the metrics is an easy step. Instead of three lines of code I can reduce it to one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded model has a test accuracy of  0.9142\n"
     ]
    }
   ],
   "source": [
    "print(\"The loaded model has a test accuracy of \", \n",
    "      sklearn.metrics.accuracy_score(y_test, \n",
    "                                     np.argmax(model(x_test), axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting\n",
    "This was actually the most challenging part of this challenge. The `model.compile` function acts on the object, and does not return itseld, making a `.compile().fit().predict()` chain impossible. I tried using Python's `map` functions, but in the end realized putting function calls in `print` also changes the object I would like to change. Here I already added the model accuracy evaluation to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3025 - accuracy: 0.9150\n",
      "None <tensorflow.python.keras.callbacks.History object at 0x7f275c0474a8> \n",
      "The loaded model has a test accuracy of  0.921\n"
     ]
    }
   ],
   "source": [
    "print(model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy']), \n",
    "      model.fit(x_train, y_train,epochs=1), \n",
    "      \"\\nThe loaded model has a test accuracy of \", \n",
    "      sklearn.metrics.accuracy_score(y_test, np.argmax(model(x_test), axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model somewhere\n",
    "So far I assumed model would be available to me. However, I need to define it on the same line. I decided to use a list-comprehension to define the model and immediately act on it. You can now even define multiple models to evaluate all of them in one line ;). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4684 - accuracy: 0.8770\n",
      "None <tensorflow.python.keras.callbacks.History object at 0x7f275c037e48> \n",
      "The loaded model has a test accuracy of  0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy']), \n",
    "      model.fit(x_train, y_train,epochs=1), \n",
    "      \"\\nThe loaded model has a test accuracy of \", \n",
    "      sklearn.metrics.accuracy_score(y_test, np.argmax(model(x_test), axis=1)))\n",
    "    for model in [tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "The last step is loading all data. Here I got pretty stuck for a while, as I initially trained on both train and test set. In the end I ended up loaded the data 4 times, to be able to do everything in one line. \n",
    "\n",
    "This bring us to the completed one line training of MNIST: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4707 - accuracy: 0.8763\n",
      "None <tensorflow.python.keras.callbacks.History object at 0x7f274c6ad438> \n",
      "The loaded model has a test accuracy of  0.9161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[print(model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy']), \n",
    "      model.fit(x_train/255.0, y_train,epochs=1), \n",
    "      \"\\nThe loaded model has a test accuracy of \", \n",
    "      sklearn.metrics.accuracy_score(y_test, np.argmax(model(x_test/255.0), axis=1)))\n",
    "    for model in [tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])]] for x_train, y_train, x_test, y_test in [(tf.keras.datasets.mnist.load_data()[0][0], \n",
    "                                                   tf.keras.datasets.mnist.load_data()[0][1],\n",
    "                                                   tf.keras.datasets.mnist.load_data()[1][0], \n",
    "                                                   tf.keras.datasets.mnist.load_data()[1][1])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Here we go, training and evaluating a character recognition program in only one line! I showed this program to some other people, who had ideas on how to make it either more readable, or shorter than what I have. If you are such a person, please consider sharing the idea on Twitter, LinkedIn, or on your own blog :). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
