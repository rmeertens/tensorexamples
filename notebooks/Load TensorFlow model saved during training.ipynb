{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading TensorFlow models saved during training\n",
    "When you are training large models on large datasets you normally do not want to wait and drink coffee while models are training. After starting a training you frequently move on to a next experiment, and check the results later. This tutorial shows you how to save models during training, and how you can later load and evaluate these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow version used in this tutorial is 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"The TensorFlow version used in this tutorial is\", tf.__version__)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Transform the input into floating point inputs between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "def get_model():\n",
    "    # Define a very simple model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28,28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "model = get_model()\n",
    "\n",
    "# Compile and train the model for one epoch... It's only to have something trained, not get the best score\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the right callback\n",
    "To save a model during training you have to add a callback to the ``model.fit`` function. You use a ``ModelCheckpoint`` callback. From the documentation, options this callback provides include:\n",
    "* Whether to only keep the model that has achieved the \"best performance\" so far, or whether to save the model at the end of every epoch regardless of performance.\n",
    "* Definition of 'best'; which quantity to monitor and whether it should be maximized or minimized.\n",
    "* The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.\n",
    "* Whether only weights are saved, or the whole model is saved.\n",
    "\n",
    "Another thing I like to do is adjust the name of the model to save. It gives you many options which help you later selecting the right model to load. From the documentation, `filepath` can contain named formatting options, which will be filled the value of `epoch` and keys in `logs` (passed in `on_epoch_end`). For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1856/1875 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9249\n",
      "Epoch 00001: saving model to saved_models/saved_model_checkpoint\n",
      "INFO:tensorflow:Assets written to: saved_models/saved_model_checkpoint/assets\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2607 - accuracy: 0.9251\n",
      "Epoch 2/5\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9653\n",
      "Epoch 00002: saving model to saved_models/saved_model_checkpoint\n",
      "INFO:tensorflow:Assets written to: saved_models/saved_model_checkpoint/assets\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1171 - accuracy: 0.9653\n",
      "Epoch 3/5\n",
      "1854/1875 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9763\n",
      "Epoch 00003: saving model to saved_models/saved_model_checkpoint\n",
      "INFO:tensorflow:Assets written to: saved_models/saved_model_checkpoint/assets\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0794 - accuracy: 0.9762\n",
      "Epoch 4/5\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9815\n",
      "Epoch 00004: saving model to saved_models/saved_model_checkpoint\n",
      "INFO:tensorflow:Assets written to: saved_models/saved_model_checkpoint/assets\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0593 - accuracy: 0.9815\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9862\n",
      "Epoch 00005: saving model to saved_models/saved_model_checkpoint\n",
      "INFO:tensorflow:Assets written to: saved_models/saved_model_checkpoint/assets\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0449 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34b808cac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'saved_models/saved_model_checkpoint'\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='train_loss', verbose=1, save_best_only=False)]\n",
    "\n",
    "model.fit(x_train, y_train,epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "To verify that the model has been saved and loaded correctly we test the accuracy of the model on the MNIST test-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded model has a test accuracy of  0.9764\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(loaded_model(x_test), axis=1)\n",
    "\n",
    "# Calculate the accuracy and confusion matrics with sklearn\n",
    "accuracy_score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"The loaded model has a test accuracy of \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
