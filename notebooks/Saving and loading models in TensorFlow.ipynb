{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models in tensorflow\n",
    "In this post I will show you how to go from training a simple neural network to saving and loading it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: train a model \n",
    "For the sake of having a model to quantize we are building a simple classifier for MNIST digits. What model you use exactly doesn't really matter, so I will take an easy one here. Feel free to experiment and make the model better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow version used in this tutorial is 2.2.0\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2611 - accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0e7907d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"The TensorFlow version used in this tutorial is\", tf.__version__)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Transform the input into floating point inputs between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "def get_model():\n",
    "    # Define a very simple model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28,28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "model = get_model()\n",
    "\n",
    "# Compile and train the model for one epoch... It's only to have something trained, not get the best score\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(x_train, y_train,epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: using Keras save function\n",
    "By default your model comes with a save function. From the documentation: \n",
    "\n",
    "This function saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
    "\n",
    "The savefile includes:\n",
    "* The model architecture, allowing to re-instantiate the model.\n",
    "* The model weights.\n",
    "* The state of the optimizer, allowing to resume training exactly where you left off.\n",
    "\n",
    "This allows you to save the entirety of the state of a model\n",
    "in a single file.\n",
    "\n",
    "Saved models can be reinstantiated via `keras.models.load_model`.\n",
    "The model returned by `load_model` is a compiled model ready to be used\n",
    "(unless the saved model was never compiled in the first place).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_models/save_load_method1/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved_models/save_load_method1\" \n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(save_path)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is particularly nice as the model remembers it's architecture. If you were not sure what number of layers you used in a saved model, this is a good method to save and restore it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: using Keras save weights\n",
    "This way you save only the layer weights. From the documentation: \n",
    "\n",
    "Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
    "argument.\n",
    "\n",
    "When saving in HDF5 format, the weight file has:\n",
    "* `layer_names` (attribute), a list of strings (ordered names of model layers).\n",
    "* For every layer, a `group` named `layer.name`\n",
    "      * For every such layer group, a group attribute `weight_names`, a list of strings (ordered names of weights tensor of the layer).\n",
    "      * For every weight in the layer, a dataset storing the weight value, named after the weight tensor.\n",
    "\n",
    "When saving in TensorFlow format, all objects referenced by the network are saved in the same format as `tf.train.Checkpoint`, including any `Layer` instances or `Optimizer` instances assigned to object attributes. For networks constructed from inputs and outputs using `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network are tracked/saved automatically. For user-defined classes which inherit from `tf.keras.Model`, `Layer` instances must be assigned to object attributes, typically in the constructor. See the documentation of `tf.train.Checkpoint` and `tf.keras.Model` for details.\n",
    "\n",
    "While the formats are the same, do not mix `save_weights` and\n",
    "`tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be loaded using `Model.load_weights`. Checkpoints saved using\n",
    "`tf.train.Checkpoint.save` should be restored using the corresponding `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over `save_weights` for training checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/save_load_method2'\n",
    "model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trained 0.1796875 Accuracy untrained 0.1796875\n"
     ]
    }
   ],
   "source": [
    "# Create the second model, but don't train it yet, so we can compare the performance to a trained model\n",
    "second_model = get_model()\n",
    "\n",
    "# Evaluate the performance of both models\n",
    "NUM_EVALUATE_SAMPLES = 128\n",
    "y_true = y_test[:NUM_EVALUATE_SAMPLES]\n",
    "y_pred_trained = np.argmax(model.predict(x_test[:NUM_EVALUATE_SAMPLES]), axis=1)\n",
    "y_pred_untrained = np.argmax(second_model.predict(x_test[:NUM_EVALUATE_SAMPLES]), axis=1)\n",
    "\n",
    "# Calculate the accuracy and confusion matrics with sklearn\n",
    "accuracy_score_trained_model = sklearn.metrics.accuracy_score(y_true, y_pred_trained)\n",
    "accuracy_score_untrained_model = sklearn.metrics.accuracy_score(y_true, y_pred_untrained)\n",
    "print(\"Accuracy trained\", accuracy_score_untrained_model, \"Accuracy untrained\", accuracy_score_untrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loading weights 0.984375\n"
     ]
    }
   ],
   "source": [
    "second_model.load_weights(save_path)\n",
    "y_pred_untrained = np.argmax(second_model.predict(x_test[:NUM_EVALUATE_SAMPLES]), axis=1)\n",
    "accuracy_score_untrained_model = sklearn.metrics.accuracy_score(y_true, y_pred_untrained)\n",
    "print(\"After loading weights\", accuracy_score_untrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the weights succesfully saved and loaded! One benefit of loading raw weights comes in when you are using custom layers in TensorFlow. In the past I experienced that the keras save function could fail or produce weird results. However, as we will see next, it is absolutely possible to save and load custom layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading custom layers\n",
    "It is even possible to define custom layers in Tensorflow, and it is also possible to save and load these custom layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "my_dense_layer (MyDenseLayer (None, 128)               100352    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,642\n",
      "Trainable params: 101,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2619 - accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0d44f79e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        multiplied = tf.matmul(input, self.kernel)\n",
    "        return tf.nn.relu(multiplied)\n",
    "        return multiplied\n",
    "\n",
    "custom_layer = MyDenseLayer(128)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28,28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        custom_layer,\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Show that we have a custom layer in there\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Show that this custom layer also achieves reasonable results\n",
    "model.fit(x_train, y_train,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/custom_model_saved/assets\n"
     ]
    }
   ],
   "source": [
    "name = 'saved_models/custom_model_saved'\n",
    "model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "my_dense_layer (MyDenseLayer (None, 128)               100352    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,642\n",
      "Trainable params: 101,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(name)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models by name\n",
    "Sometimes, when working on transfer learning, or when you have a solid backbone trained for your model you would like to reuse, you want to only load specific weights. \n",
    "\n",
    "Pay special attention to the fact that only topological loading (`by_name=False`) is supported when loading weights\n",
    "from the TensorFlow format. To load weights by name you have to make sure the save_name ends with 'h5', or you define the save_format argument when saving the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "first_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "head_1 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output_a (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "first_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "head_2_1 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "head_2_2 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output_a (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28,28), name='input'),\n",
    "        tf.keras.layers.Flatten(name='flatten'),\n",
    "        tf.keras.layers.Dense(128,activation='relu', name='first_layer'),\n",
    "        tf.keras.layers.Dense(128,activation='relu', name='head_1'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output_a')\n",
    "    ])\n",
    "model.summary()\n",
    "\n",
    "save_name = 'saved_models/save_load_by_name.h5'\n",
    "model.save_weights(save_name)\n",
    "\n",
    "second_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28,28),name='input'),\n",
    "        tf.keras.layers.Flatten(name='flatten'),\n",
    "        tf.keras.layers.Dense(128,activation='relu', name='first_layer'),\n",
    "        tf.keras.layers.Dense(128,activation='relu', name='head_2_1'),\n",
    "        tf.keras.layers.Dense(128,activation='relu', name='head_2_2'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output_a')\n",
    "    ])\n",
    "second_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model.load_weights(save_name, by_name=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
